{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_rnn import load_ndfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDFA\n",
    "x_train, (i2w, w2i) = load_ndfa(n=150_000)\n",
    "\n",
    "# # Brackets\n",
    "# x_train, (i2w, w2i) = load_brackets(n=150_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "print(''.join([i2w[i] for i in  x_train[10_000]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(w2i)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.pad': 0,\n",
       " '.start': 1,\n",
       " '.end': 2,\n",
       " '.unk': 3,\n",
       " '!': 4,\n",
       " 'b': 5,\n",
       " 'v': 6,\n",
       " 's': 7,\n",
       " 'c': 8,\n",
       " 'u': 9,\n",
       " 'a': 10,\n",
       " 'm': 11,\n",
       " 'w': 12,\n",
       " 'k': 13,\n",
       " 'l': 14}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_seq_length(batch):\n",
    "    return max(len(seq) for seq in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_seq_lengths(batch):\n",
    "    return sum(len(seq) for seq in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(seq, amt=1):\n",
    "    for _ in range(amt):\n",
    "        seq.append(w2i['.pad'])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start(seq):\n",
    "    seq.insert(0, w2i['.start'])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end(seq):\n",
    "    seq.append(w2i['.end'])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_seq_length(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.96264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sum_seq_lengths(x_train) / len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    max_len = get_max_seq_length(batch)\n",
    "    \n",
    "    upd_batch = []\n",
    "    for i, _ in enumerate(batch):\n",
    "        seq = batch[i].copy()\n",
    "        seq = add_start(seq)\n",
    "        seq = add_end(seq)\n",
    "        seq = add_padding(seq, amt=max_len + 2 - len(seq))\n",
    "        upd_batch.append(seq)\n",
    "    \n",
    "    upd_batch = torch.tensor(upd_batch, dtype=torch.long)\n",
    "    # targets = torch.tensor(targets, dtype=torch.long)\n",
    "    \n",
    "    # return upd_batch, targets\n",
    "    return upd_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, vocab_size, token_amt=12500):\n",
    "    batches = []\n",
    "    targets = []\n",
    "\n",
    "    bound_l, bound_r = -1, 0\n",
    "    idx = 0\n",
    "    while bound_r < len(data):\n",
    "        bound_l = bound_r\n",
    "\n",
    "        num_of_tokens = 0\n",
    "        while (num_of_tokens + len(data[idx])) < token_amt and bound_r < len(data):\n",
    "            num_of_tokens += len(data[idx])\n",
    "            bound_r += 1\n",
    "        print(bound_l, bound_r)\n",
    "        batch = data[bound_l:bound_r]\n",
    "        batch = preprocess_batch(batch)\n",
    "        target = F.pad(batch, (0, 1), \"constant\", 0)[:, 1:]\n",
    "        target = F.one_hot(target, num_classes=vocab_size)\n",
    "\n",
    "        batches.append(batch)\n",
    "        targets.append(target)\n",
    "    return batches, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6249\n",
      "6249 12498\n",
      "12498 18747\n",
      "18747 24996\n",
      "24996 31245\n",
      "31245 37494\n",
      "37494 43743\n",
      "43743 49992\n",
      "49992 56241\n",
      "56241 62490\n",
      "62490 68739\n",
      "68739 74988\n",
      "74988 81237\n",
      "81237 87486\n",
      "87486 93735\n",
      "93735 99984\n",
      "99984 106233\n",
      "106233 112482\n",
      "112482 118731\n",
      "118731 124980\n",
      "124980 131229\n",
      "131229 137478\n",
      "137478 143727\n",
      "143727 149976\n",
      "149976 150000\n"
     ]
    }
   ],
   "source": [
    "batches, targets = get_batches(x_train, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2],\n",
       "        [1, 7, 7, 2]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_size,\n",
    "                 hidden_size,\n",
    "                 lstm_num_layers) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, lstm_num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = self.embed(x)\n",
    "        lstm_output, (hn, cn) = self.lstm(input)\n",
    "        output = self.linear(lstm_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(w2i)\n",
    "embedding_size = 32\n",
    "hidden_size = 16\n",
    "lstm_num_layers = 1\n",
    "\n",
    "epochs = 3\n",
    "learning_rate = 0.001\n",
    "device='cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(vocab_size, embedding_size, hidden_size, lstm_num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embed): Embedding(15, 32)\n",
       "  (lstm): LSTM(32, 16, batch_first=True)\n",
       "  (linear): Linear(in_features=16, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batches, targets):\n",
    "    indices = list(range(len(batches)))\n",
    "    random.shuffle(indices)\n",
    "    for ind in indices:\n",
    "        yield batches[ind], targets[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6249, 4, 15])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = net(batches[0])\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0].size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0].size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34548.4894, dtype=torch.float64, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(outputs, targets[0].type(torch.float64))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, batches, targets, epochs=3, learning_rate=0.001, device='cpu'):\n",
    "    # Loss function:\n",
    "    # check whether the loss function applies softmax or whether we need to do it manually\n",
    "    # loss function = cross entropy loss at every point in time, read doc to figure out\n",
    "    # how to shuffle dimensions properly\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum') # 'sum': the output will be summed, since we want loss on every step\n",
    "\n",
    "    # Optimizer:\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    metrics = {\n",
    "        'loss_history': [],\n",
    "        'loss_train': []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "        start_time = time()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (X, y) in enumerate(batch_generator(batches, targets)):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y.type(torch.float64))\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            finish_time = time()\n",
    "\n",
    "            # print statistics\n",
    "            total_loss += loss.item() / y.size()[0] / y.size()[-1]\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss.item() / y.size()[0] / y.size()[-1]:.3f} time: {finish_time - start_time:.3f}')\n",
    "            metrics['loss_history'].append(loss.item())\n",
    "\n",
    "        metrics['loss_train'].append(total_loss / len(x_train))\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "\n",
    "        # print(\"Predicting:\")\n",
    "        # model.eval()\n",
    "        # seq = ['.start', 'a', 'b']\n",
    "        # predict(model, dataset, seq, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [88], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m Net(vocab_size, embedding_size, hidden_size, lstm_num_layers)\n\u001b[0;32m----> 2\u001b[0m model, metrics \u001b[39m=\u001b[39m train(model, batches, targets, epochs, learning_rate, device)\n",
      "Cell \u001b[0;32mIn [87], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, batches, targets, epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m finish_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m     37\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m targets\u001b[39m.\u001b[39;49msize()[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m targets[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mi \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m5d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m targets\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m targets[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m time: \u001b[39m\u001b[39m{\u001b[39;00mfinish_time \u001b[39m-\u001b[39m start_time\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m metrics[\u001b[39m'\u001b[39m\u001b[39mloss_history\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model = Net(vocab_size, embedding_size, hidden_size, lstm_num_layers)\n",
    "model, metrics = train(model, batches, targets, epochs, learning_rate, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80529b423b53fd639a6f5f2af8b83afb67b7ac3506cc89d37f7746dba0566c4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
